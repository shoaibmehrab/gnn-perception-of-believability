{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import pickle\n",
        "import os\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_MIB_Kcp6DUv",
        "outputId": "b96d2ace-7517-4b75-b330-4cd0ad952d8f"
      },
      "outputs": [],
      "source": [
        "path_to_processed_dataset_folder = '/home/shoaib/gnn/gcn/datasets'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Directory exists\n"
          ]
        }
      ],
      "source": [
        "if os.path.exists(path_to_processed_dataset_folder):\n",
        "  print(\"Directory exists\")\n",
        "else:\n",
        "  print(\"Directory not exists\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vlYoSb75dPb7",
        "outputId": "29ed1269-deb3-4d35-e7d7-ea054348647d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch_geometric in /home/shoaib/anaconda3/lib/python3.11/site-packages (2.5.2)\n",
            "Requirement already satisfied: tqdm in /home/shoaib/anaconda3/lib/python3.11/site-packages (from torch_geometric) (4.65.0)\n",
            "Requirement already satisfied: numpy in /home/shoaib/anaconda3/lib/python3.11/site-packages (from torch_geometric) (1.24.3)\n",
            "Requirement already satisfied: scipy in /home/shoaib/anaconda3/lib/python3.11/site-packages (from torch_geometric) (1.11.1)\n",
            "Requirement already satisfied: fsspec in /home/shoaib/anaconda3/lib/python3.11/site-packages (from torch_geometric) (2023.4.0)\n",
            "Requirement already satisfied: jinja2 in /home/shoaib/anaconda3/lib/python3.11/site-packages (from torch_geometric) (3.1.2)\n",
            "Requirement already satisfied: aiohttp in /home/shoaib/anaconda3/lib/python3.11/site-packages (from torch_geometric) (3.8.5)\n",
            "Requirement already satisfied: requests in /home/shoaib/anaconda3/lib/python3.11/site-packages (from torch_geometric) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /home/shoaib/anaconda3/lib/python3.11/site-packages (from torch_geometric) (3.0.9)\n",
            "Requirement already satisfied: scikit-learn in /home/shoaib/anaconda3/lib/python3.11/site-packages (from torch_geometric) (1.3.0)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /home/shoaib/anaconda3/lib/python3.11/site-packages (from torch_geometric) (5.9.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /home/shoaib/anaconda3/lib/python3.11/site-packages (from aiohttp->torch_geometric) (22.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /home/shoaib/anaconda3/lib/python3.11/site-packages (from aiohttp->torch_geometric) (2.0.4)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /home/shoaib/anaconda3/lib/python3.11/site-packages (from aiohttp->torch_geometric) (6.0.2)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/shoaib/anaconda3/lib/python3.11/site-packages (from aiohttp->torch_geometric) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /home/shoaib/anaconda3/lib/python3.11/site-packages (from aiohttp->torch_geometric) (1.8.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /home/shoaib/anaconda3/lib/python3.11/site-packages (from aiohttp->torch_geometric) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /home/shoaib/anaconda3/lib/python3.11/site-packages (from aiohttp->torch_geometric) (1.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /home/shoaib/anaconda3/lib/python3.11/site-packages (from jinja2->torch_geometric) (2.1.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/shoaib/anaconda3/lib/python3.11/site-packages (from requests->torch_geometric) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/shoaib/anaconda3/lib/python3.11/site-packages (from requests->torch_geometric) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/shoaib/anaconda3/lib/python3.11/site-packages (from requests->torch_geometric) (2023.7.22)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /home/shoaib/anaconda3/lib/python3.11/site-packages (from scikit-learn->torch_geometric) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/shoaib/anaconda3/lib/python3.11/site-packages (from scikit-learn->torch_geometric) (2.2.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install torch_geometric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "FydmLUiNOBSA"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch_geometric.utils import add_self_loops, coalesce\n",
        "from torch_geometric.data import Data\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch_geometric.utils import index_to_mask\n",
        "from torch_geometric.nn import SAGEConv\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.manual_seed(0)\n",
        "np.random.seed(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Read the CSV files into DataFrames\n",
        "user_df = pd.read_csv(f'{path_to_processed_dataset_folder}/user_features_processed.csv', header = 0)\n",
        "news_df = pd.read_csv(f'{path_to_processed_dataset_folder}/news_features_processed.csv', header = 0)\n",
        "\n",
        "# Remove duplicates based on the first column\n",
        "user_df = user_df.drop_duplicates(subset=[user_df.columns[0]])\n",
        "news_df = news_df.drop_duplicates(subset=[news_df.columns[0]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load user and news features, excluding the first column\n",
        "user_features = user_df.values[:, 1:]\n",
        "news_features = news_df.values[:, 1:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get the usernames and newsnames\n",
        "usernames = user_df.values[:, 0]\n",
        "newsnames = news_df.values[:, 0]\n",
        "\n",
        "# Create the username_to_index and newsname_to_index dictionaries\n",
        "username_to_index = {username: index for index, username in enumerate(usernames)}\n",
        "newsname_to_index = {filename: index + len(usernames) for index, filename in enumerate(newsnames)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Read the relationship file into a DataFrame\n",
        "relationship_df = pd.read_csv(f'{path_to_processed_dataset_folder}/relationship_user_and_news_v2.csv')\n",
        "\n",
        "# Remove duplicates based on the username\n",
        "relationship_df = relationship_df.drop_duplicates(subset=['username'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>username</th>\n",
              "      <th>filename</th>\n",
              "      <th>label</th>\n",
              "      <th>human_evaluation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>JcKatherine</td>\n",
              "      <td>politifact13816</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>bjr1961</td>\n",
              "      <td>politifact13816</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>SherryAva</td>\n",
              "      <td>politifact13816</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>linnflux</td>\n",
              "      <td>politifact13816</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>po_murray</td>\n",
              "      <td>politifact13816</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14530</th>\n",
              "      <td>Omwenga</td>\n",
              "      <td>politifact12721</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14531</th>\n",
              "      <td>MarkPaleo</td>\n",
              "      <td>politifact12721</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14532</th>\n",
              "      <td>einerdrake</td>\n",
              "      <td>politifact12721</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14533</th>\n",
              "      <td>Corinne4Hillary</td>\n",
              "      <td>politifact12721</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14534</th>\n",
              "      <td>paulcadario</td>\n",
              "      <td>politifact12721</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>13154 rows Ã— 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "              username         filename  label  human_evaluation\n",
              "0          JcKatherine  politifact13816    0.0                 4\n",
              "1              bjr1961  politifact13816    0.0                 4\n",
              "2            SherryAva  politifact13816    0.0                 4\n",
              "3             linnflux  politifact13816    0.0                 4\n",
              "4            po_murray  politifact13816    0.0                 4\n",
              "...                ...              ...    ...               ...\n",
              "14530          Omwenga  politifact12721    1.0                 3\n",
              "14531        MarkPaleo  politifact12721    1.0                 3\n",
              "14532       einerdrake  politifact12721    1.0                 4\n",
              "14533  Corinne4Hillary  politifact12721    1.0                 5\n",
              "14534      paulcadario  politifact12721    1.0                 4\n",
              "\n",
              "[13154 rows x 4 columns]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "relationship_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Xi_nu8mZbXvJ"
      },
      "outputs": [],
      "source": [
        "# Create adjacency matrix\n",
        "\n",
        "#calculates the total number of nodes in the graph, which is the sum of the number of users (len(usernames)) and the number of news items (len(newsnames)).\n",
        "num_nodes = len(usernames) + len(newsnames)\n",
        "\n",
        "\"\"\"\n",
        "initializes an adjacency matrix as a 2D NumPy array of zeros with shape (num_nodes, num_nodes).\n",
        "This creates a square matrix with dimensions equal to the total number of nodes in the graph.\n",
        "The matrix is initially filled with zeros, indicating that there are no edges between any pair of nodes.\n",
        "\"\"\"\n",
        "\n",
        "adjacency_matrix = np.zeros((num_nodes, num_nodes))\n",
        "\n",
        "\"\"\"\n",
        "iterates over the rows of the relationship_df DataFrame, which contains the relationships between users \n",
        "and news items. For each row, it gets the indices of the user and the news item in the username_to_index and newsname_to_index \n",
        "dictionaries, respectively. These indices correspond to the positions of the user and the news item in the adjacency matrix.\n",
        "Finally, it sets the element of the adjacency matrix at the position (user_id, news_id) to 1, indicating that there is \n",
        "an edge between the user and the news item. This is done for every row in the relationship_df DataFrame, effectively filling \n",
        "in the adjacency matrix with the relationships between users and news items.\n",
        "At the end of this code block, adjacency_matrix is a 2D NumPy array that represents the graph of users and news items. If there \n",
        "is a relationship between a user and a news item, the corresponding element in the adjacency matrix is 1; otherwise, it is 0.\n",
        "\"\"\"\n",
        "\n",
        "for _, row in relationship_df.iterrows():\n",
        "    user_id = username_to_index[row['username']]\n",
        "    news_id = newsname_to_index[row['filename']]\n",
        "    adjacency_matrix[user_id, news_id] = 1\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9uqUu71b5fV",
        "outputId": "9b3b6f1a-fb5c-47c6-ece4-d36b25c03a32"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]])"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "adjacency_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize the edge attribute matrix with zeros\n",
        "edge_attr_matrix = np.zeros((num_nodes, num_nodes))\n",
        "\n",
        "# Fill the edge attribute matrix with human survey values\n",
        "for _, row in relationship_df.iterrows():\n",
        "    user_id = username_to_index[row['username']]\n",
        "    news_id = newsname_to_index[row['filename']]\n",
        "    survey_value = row['human_evaluation'] \n",
        "    edge_attr_matrix[user_id, news_id] = survey_value\n",
        "\n",
        "# Convert the edge attribute matrix into a tensor\n",
        "edge_attr_matrix = np.eye(num_nodes) + edge_attr_matrix  # Add self-loops\n",
        "edge_attr = torch.tensor(edge_attr_matrix[edge_attr_matrix.nonzero()], dtype=torch.float, requires_grad=True)\n",
        "\n",
        "# # Flatten the edge_attr tensor to make it 1D\n",
        "# edge_attr = edge_attr.flatten()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "zkYH0pNmcdFj"
      },
      "outputs": [],
      "source": [
        "# Load node attributes, adjacency matrix, and labels from .npy files\n",
        "node_attributes = np.load(f'{path_to_processed_dataset_folder}/node_attributes.npy', allow_pickle = True)\n",
        "adj = np.load(f'{path_to_processed_dataset_folder}/adjacency_matrix.npy', allow_pickle = True)\n",
        "y = np.load(f'{path_to_processed_dataset_folder}/labels_v2.npy', allow_pickle = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4KAUfzR4gIL2",
        "outputId": "739e9285-2934-4ebe-f1b0-8534208fbdfb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1.27, 11122.0, 11272.0, ..., 0.0, 0.0, 0.0],\n",
              "       [1.06, 267.0, 1359.0, ..., 0.0, 0.0, 0.0],\n",
              "       [1.33, 537.0, 409.0, ..., 0.0, 0.0, 0.0],\n",
              "       ...,\n",
              "       [14.511231890100216, 47.83230057107836, 14.0091382248733, ...,\n",
              "        1.42, 0.94, 0.24],\n",
              "       [13.5591, 45.29501831501835, 14.264175824175828, ..., 0.0, 0.0,\n",
              "        1.01],\n",
              "       [12.254254345995212, 61.67082158675014, 10.53875914973744, ...,\n",
              "        1.4, 0.06, 2.02]], dtype=object)"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "node_attributes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vpfRWLWPdtTx",
        "outputId": "48a3eeec-b135-4bad-d6e8-eed597480d35"
      },
      "outputs": [],
      "source": [
        "# Convert adjacency matrix to edge index\n",
        "edge_index = torch.tensor(adj.nonzero(), dtype=torch.long)\n",
        "\n",
        "# Convert node attributes to tensor\n",
        "node_attributes = node_attributes.astype(np.float32)\n",
        "x = torch.from_numpy(node_attributes).to(torch.float)\n",
        "\n",
        "# Add self loops to the edge index\n",
        "edge_index, _ = add_self_loops(edge_index, None)\n",
        "\n",
        "# Coalesce the edge index\n",
        "num_nodes = x.size(0)\n",
        "edge_index, _ = coalesce(edge_index, None, num_nodes, num_nodes)\n",
        "\n",
        "# Convert labels to tensor and pad with zeros\n",
        "y = torch.from_numpy(y.squeeze()).to(torch.long)\n",
        "#y = torch.cat((y, torch.zeros(num_nodes - y.size()[0], dtype=torch.long)))\n",
        "\n",
        "# Create Data object\n",
        "data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[    0,     0,     1,  ..., 13337, 13338, 13339],\n",
            "        [    0, 13202,     1,  ..., 13337, 13338, 13339]])\n",
            "2\n",
            "26494\n"
          ]
        }
      ],
      "source": [
        "print(edge_index)\n",
        "print(len(edge_index))\n",
        "print(edge_index.shape[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5TnEKLBtiQ0E",
        "outputId": "a4f5cb10-5b28-4d75-d8fd-8c00c32b016b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "26494"
            ]
          },
          "execution_count": 78,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "edge_attr.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hyHzx60Digpj",
        "outputId": "39649979-25ed-426b-bffc-f8e414b0d71d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "13340"
            ]
          },
          "execution_count": 76,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y.size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kXxzWSaBiWGb",
        "outputId": "8699cb0f-fdaf-4426-cde7-6cdb66cc8193"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "138"
            ]
          },
          "execution_count": 77,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x.size(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9uZqscJiZng",
        "outputId": "391595de-4065-4e8e-fbf8-dadf1b04a7e7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([2, 26494])"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "edge_index.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "mBX1Ywo5gmmn"
      },
      "outputs": [],
      "source": [
        "train_per = 0.8  # Adjust as needed\n",
        "\n",
        "y = np.array(y)\n",
        "X_train, X_test, y_train, y_test = train_test_split(range(y.size), y.squeeze(),\n",
        "                                                    test_size=1 - train_per - 0.1, random_state=42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train,\n",
        "                                                  test_size=train_per / (train_per + 0.1), random_state=42)\n",
        "\n",
        "train_index = torch.tensor(X_train, dtype=torch.long)\n",
        "val_index = torch.tensor(X_val, dtype=torch.long)\n",
        "test_index = torch.tensor(X_test, dtype=torch.long)\n",
        "\n",
        "train_mask = index_to_mask(train_index, size=num_nodes)\n",
        "val_mask = index_to_mask(val_index, size=num_nodes)\n",
        "test_mask = index_to_mask(test_index, size=num_nodes)\n",
        "\n",
        "data.train_mask = train_mask\n",
        "data.val_mask = val_mask\n",
        "data.test_mask = test_mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tOjcQ_lnrPRf",
        "outputId": "5a157310-790b-4cf3-bfe0-6e2ca165fc23"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2 2 2 ... 1 1 1]\n"
          ]
        }
      ],
      "source": [
        "print(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of x: torch.Size([13340, 138])\n",
            "Shape of edge_index: torch.Size([2, 26494])\n",
            "Shape of edge_attr: torch.Size([26494])\n"
          ]
        }
      ],
      "source": [
        "print(\"Shape of x:\", x.shape)\n",
        "print(\"Shape of edge_index:\", edge_index.shape)\n",
        "print(\"Shape of edge_attr:\", edge_attr.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "YNaBPWf-hfEU"
      },
      "outputs": [],
      "source": [
        "from torch_scatter import scatter_add\n",
        "class EdgeAttrSAGEConv(SAGEConv):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(EdgeAttrSAGEConv, self).__init__(in_channels, out_channels)\n",
        "        # Assuming edge_attr is 1-dimensional, if it's not, adjust the in_features accordingly\n",
        "        self.edge_attr_lin = torch.nn.Linear(1, out_channels)\n",
        "\n",
        "    def forward(self, x, edge_index, edge_attr):\n",
        "        # Add self-loops to the adjacency matrix.\n",
        "        edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))\n",
        "\n",
        "        # Multiply edge attributes by the node features before aggregation.\n",
        "        row, col = edge_index\n",
        "        edge_attr = self.edge_attr_lin(edge_attr.view(-1, 1))\n",
        "        x_j = x[col] * edge_attr\n",
        "\n",
        "        # Aggregate edge attributes using the 'add' operation.\n",
        "        aggr_out = scatter_add(x_j, row, dim=0, dim_size=x.size(0))\n",
        "\n",
        "        # Combine the aggregated edge attributes with the node features.\n",
        "        out = self.propagate(edge_index, x=x, size=None)\n",
        "        out += aggr_out\n",
        "\n",
        "        return out\n",
        "\n",
        "class SAGE(torch.nn.Module):\n",
        "    def __init__(self, num_features, num_classes):\n",
        "        super(SAGE, self).__init__()\n",
        "        self.conv1 = EdgeAttrSAGEConv(num_features, 128)\n",
        "        self.conv2 = EdgeAttrSAGEConv(128, num_classes)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr\n",
        "\n",
        "        x = self.conv1(x, edge_index, edge_attr)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x, edge_index, edge_attr)\n",
        "\n",
        "        return F.log_softmax(x, dim=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QhpENQwJkbp0",
        "outputId": "cedecf36-5899-44b0-dbbc-4312c37e4686"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "num_classes = len(np.unique(y))  # Adjust as needed\n",
        "num_classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "id": "fzjYB7MIkO8f"
      },
      "outputs": [],
      "source": [
        "\n",
        "model = SAGE(num_features=x.size(1), num_classes=num_classes)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "LsCxCuIlkyLx"
      },
      "outputs": [],
      "source": [
        "# # loss function optimization considering the weight distribution  \n",
        "\n",
        "# from torch import device\n",
        "\n",
        "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# def train():\n",
        "#     model.train()\n",
        "#     optimizer.zero_grad()\n",
        "#     out = model(data)\n",
        "#     weights = torch.tensor([200.0, 200.0, 0.1]).to(device)\n",
        "#     loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask], weight=weights)\n",
        "#     loss.backward()\n",
        "#     optimizer.step()\n",
        "#     return loss.item()\n",
        "\n",
        "\n",
        "# def test(mask):\n",
        "#     model.eval()\n",
        "#     with torch.no_grad():\n",
        "#         logits = model(data)\n",
        "#         preds = logits.max(dim=1)[1]\n",
        "#         correct = preds[mask].eq(data.y[mask]).sum().item()\n",
        "#         acc = correct / mask.sum().item()\n",
        "#         return acc, preds[mask], data.y[mask]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {},
      "outputs": [],
      "source": [
        "# loss function optimization considering the only two classes \n",
        "\n",
        "def train():\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    out = model(data)\n",
        "    \n",
        "    # Create a mask for the fake and real news\n",
        "    news_mask = (data.y[data.train_mask] == 0) | (data.y[data.train_mask] == 1)\n",
        "    \n",
        "    # Apply the mask to the output and labels\n",
        "    out_news = out[data.train_mask][news_mask]\n",
        "    labels_news = data.y[data.train_mask][news_mask]\n",
        "    \n",
        "    # Compute the loss only for the fake and real news\n",
        "    loss = F.nll_loss(out_news, labels_news)\n",
        "    \n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item()\n",
        "\n",
        "def test(mask):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        logits = model(data)\n",
        "        preds = logits.max(dim=1)[1]\n",
        "        \n",
        "        # Create a mask for the fake and real news\n",
        "        news_mask = (data.y[mask] == 0) | (data.y[mask] == 1)\n",
        "        \n",
        "        # Apply the mask to the predictions and labels\n",
        "        preds_news = preds[mask][news_mask]\n",
        "        labels_news = data.y[mask][news_mask]\n",
        "        \n",
        "        correct = preds_news.eq(labels_news).sum().item()\n",
        "        acc = correct / news_mask.sum().item()\n",
        "        return acc, preds_news, labels_news\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZNOoKrVdk22e",
        "outputId": "4965099e-bab0-46cc-b34a-6cdb93d001d3"
      },
      "outputs": [],
      "source": [
        "# # General training appraoch\n",
        "\n",
        "# for epoch in range(1, 150):\n",
        "#     loss = train()\n",
        "#     train_acc, _, _ = test(data.train_mask)\n",
        "#     val_acc, _, _ = test(data.val_mask)\n",
        "#     test_acc, preds, labels = test(data.test_mask)\n",
        "#     print(f'Epoch: {epoch}, Loss: {loss:.4f}, Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}, Test Acc: {test_acc:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {},
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "The size of tensor a (138) must match the size of tensor b (128) at non-singleton dimension 1",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[121], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m wait \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m500\u001b[39m):\n\u001b[0;32m---> 10\u001b[0m     loss \u001b[38;5;241m=\u001b[39m train()\n\u001b[1;32m     11\u001b[0m     train_acc, _, _ \u001b[38;5;241m=\u001b[39m test(data\u001b[38;5;241m.\u001b[39mtrain_mask)\n\u001b[1;32m     12\u001b[0m     val_acc, _, _ \u001b[38;5;241m=\u001b[39m test(data\u001b[38;5;241m.\u001b[39mval_mask)\n",
            "Cell \u001b[0;32mIn[120], line 6\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m      5\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m----> 6\u001b[0m out \u001b[38;5;241m=\u001b[39m model(data)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Create a mask for the fake and real news\u001b[39;00m\n\u001b[1;32m      9\u001b[0m news_mask \u001b[38;5;241m=\u001b[39m (data\u001b[38;5;241m.\u001b[39my[data\u001b[38;5;241m.\u001b[39mtrain_mask] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m|\u001b[39m (data\u001b[38;5;241m.\u001b[39my[data\u001b[38;5;241m.\u001b[39mtrain_mask] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "Cell \u001b[0;32mIn[118], line 35\u001b[0m, in \u001b[0;36mSAGE.forward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, data):\n\u001b[1;32m     33\u001b[0m     x, edge_index, edge_attr \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mx, data\u001b[38;5;241m.\u001b[39medge_index, data\u001b[38;5;241m.\u001b[39medge_attr\n\u001b[0;32m---> 35\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1(x, edge_index, edge_attr)\n\u001b[1;32m     36\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(x)\n\u001b[1;32m     37\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(x, edge_index, edge_attr)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "Cell \u001b[0;32mIn[118], line 15\u001b[0m, in \u001b[0;36mEdgeAttrSAGEConv.forward\u001b[0;34m(self, x, edge_index, edge_attr)\u001b[0m\n\u001b[1;32m     13\u001b[0m row, col \u001b[38;5;241m=\u001b[39m edge_index\n\u001b[1;32m     14\u001b[0m edge_attr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39medge_attr_lin(edge_attr\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m---> 15\u001b[0m x_j \u001b[38;5;241m=\u001b[39m x[col] \u001b[38;5;241m*\u001b[39m edge_attr\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Aggregate edge attributes using the 'add' operation.\u001b[39;00m\n\u001b[1;32m     18\u001b[0m aggr_out \u001b[38;5;241m=\u001b[39m scatter_add(x_j, row, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, dim_size\u001b[38;5;241m=\u001b[39mx\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m))\n",
            "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (138) must match the size of tensor b (128) at non-singleton dimension 1"
          ]
        }
      ],
      "source": [
        "# Best accuracy from epochs\n",
        "\n",
        "best_acc = 0.0\n",
        "best_epoch = 0\n",
        "best_state_dict = None\n",
        "patience = 100  # Number of epochs to wait for improvement before stopping\n",
        "wait = 0\n",
        "\n",
        "for epoch in range(1, 500):\n",
        "    loss = train()\n",
        "    train_acc, _, _ = test(data.train_mask)\n",
        "    val_acc, _, _ = test(data.val_mask)\n",
        "    test_acc, preds, labels = test(data.test_mask)\n",
        "    \n",
        "    # Save the model parameters if this epoch has the best accuracy\n",
        "    if val_acc > best_acc:\n",
        "        best_acc = val_acc\n",
        "        best_epoch = epoch\n",
        "        best_state_dict = model.state_dict()\n",
        "        wait = 0  # Reset the counter\n",
        "    else:\n",
        "        wait += 1  # Increment the counter if no improvement\n",
        "    \n",
        "    print(f'Epoch: {epoch}, Loss: {loss:.4f}, Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}, Test Acc: {test_acc:.4f}')\n",
        "    \n",
        "    # Stop training if no improvement for 'patience' epochs\n",
        "    if wait >= patience:\n",
        "        print(f'Early stopping at epoch {epoch}')\n",
        "        break\n",
        "\n",
        "print(f'Best Val Acc: {best_acc} at Epoch: {best_epoch}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "path_to_saved_model_folder = '/home/shoaib/gnn/gcn/saved-models'\n",
        "model_name = 'SAGE_model_human_evaluation_128'\n",
        "path = f'{path_to_saved_model_folder}/{model_name}.pth'\n",
        "\n",
        "torch.save(best_state_dict, path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Final Test Accuracy: 0.7894736842105263\n",
            "Final Test F1 Score: 0.7918128654970761\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.6364    1.0000    0.7778         7\n",
            "           1     1.0000    0.6667    0.8000        12\n",
            "\n",
            "    accuracy                         0.7895        19\n",
            "   macro avg     0.8182    0.8333    0.7889        19\n",
            "weighted avg     0.8660    0.7895    0.7918        19\n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAv8AAAJfCAYAAADo57nMAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAApuUlEQVR4nO3deZhU5Zk34KfYCkRsB1kEg4g6GRGVIEwMuEclIWrky8Ro3HBBQ8IkmnYb1AhkdFpnEsW4EMEALnFLVFxGTVAvtxDCIji4L6CoAQkxgna0gK76/nDCnA6gVU13V5+u+851/ujTdd7zwJULn/71c96TKRQKhQAAAFq9NuUuAAAAaB6afwAAqBCafwAAqBCafwAAqBCafwAAqBCafwAAqBCafwAAqBCafwAAqBCafwAAqBCafwAAqBCafwAASIH169fHRRddFP369YtOnTrFzjvvHD/+8Y8jn88XvUa7JqwPAABoJJdffnn8/Oc/jxtvvDEGDBgQ8+fPj1NOOSWqqqrizDPPLGoNzT8AAKTA73//+zjqqKPi8MMPj4iInXbaKW677baYP39+0WsY+wEAgDLJ5XKxZs2aekcul9vkZ/fbb7949NFH45VXXomIiGeffTaefvrp+NrXvlb0/Vpl8v/Ro1PKXQJAo+oyYmK5SwBoVOvXvlPuEjZr3aolzXavmmtuiokT6/8bP378+JgwYcJGnz3//PNj9erVsdtuu0Xbtm2jrq4uLr300vj2t79d9P1aZfMPAABpMG7cuKiurq53LpvNbvKzd9xxR9xyyy1x6623xoABA2LRokVx1llnRe/evWPUqFFF3U/zDwAASfm6ZrtVNpvdbLP/984999z4t3/7tzj22GMjImLPPfeMN998M2pqaopu/s38AwBACvz1r3+NNm3qt+9t27a11ScAADRYofhmujkdeeSRcemll8aOO+4YAwYMiIULF8YVV1wRp556atFraP4BACAFrr766vjRj34U3/ve92LlypXRu3fv+M53vhMXX3xx0WtkCoVCoQlrLAu7/QCtjd1+gNamRe/2s/zFZrtX+179m+1eEWb+AQCgYhj7AQCAhEILnflvDJJ/AACoEJJ/AABIKmHrzLSR/AMAQIWQ/AMAQJKZfwAAIO0k/wAAkJSvK3cFTUbyDwAAFULzDwAAFcLYDwAAJHngFwAASDvJPwAAJHnJFwAAkHaSfwAASCiY+QcAANJO8g8AAElm/gEAgLST/AMAQJKZfwAAIO0k/wAAkJSvK3cFTUbyDwAAFULyDwAASWb+AQCAtJP8AwBAkn3+AQCAtJP8AwBAkpl/AAAg7TT/AABQIYz9AABAkgd+AQCAtJP8AwBAQqFQV+4SmozkHwAAKoTkHwAAkmz1CQAApJ3kHwAAkuz2AwAApJ3kHwAAksz8AwAAaSf5BwCApLx9/gEAgJST/AMAQJKZfwAAIO0k/wAAkGSffwAAIO0k/wAAkGTmHwAASDvJPwAAJJn5BwAA0k7zDwAAFcLYDwAAJBn7AQAA0k7yDwAACYVCXblLaDKSfwAAqBCSfwAASDLzDwAApJ3mHwAAkgr55jtKsNNOO0Umk9noGDt2bNFrGPsBAIAUmDdvXtTV/d/DyM8991wcdthhcfTRRxe9huYfAACSWujMf/fu3et9fdlll8Uuu+wSBx54YNFraP4BAKBMcrlc5HK5euey2Wxks9lPvW7t2rVxyy23RHV1dWQymaLvZ+YfAACSmnHmv6amJqqqquodNTU1n1nizJkz4/3334+TTz65pD9aplAoFBr419JiffTolHKXANCouoyYWO4SABrV+rXvlLuEzfrokZ83273a7H9Kg5L/r3zlK9GhQ4e4//77S7qfsR8AAEhqxpn/Yhr9v/fmm2/GI488EnfffXfJ9zP2AwAAKTJ9+vTo0aNHHH744SVfK/kHAICkEvffb075fD6mT58eo0aNinbtSm/lJf8AAJASjzzySCxbtixOPfXUBl0v+QcAgKQWus9/RMTw4cNjS/brkfwDAECF0PwDAECFMPYDAABJLXjsZ0tJ/gEAoEJI/gEAIKkFb/W5pST/AABQIST/AACQZOYfAABIO8k/AAAkmfkHAADSTvIPAABJZv4BAIC0k/wDAECSmX8AACDtJP8AAJBk5h8AAEg7yT8AACRJ/gEAgLST/AMAQFKhUO4KmozkHwAAKoTkHwAAksz8AwAAaaf5BwCACmHsBwAAkoz9AAAAaSf5BwCApILkHwAASDnJPwAAJJn5BwAA0k7yDwAASYVCuStoMpJ/AACoEJJ/AABIMvMPAACkneQfAACSJP8AAEDaSf4BACDJG34BAIC0k/wDAEBCIW+ffwAAIOUk/wAAkGS3HwAAIO00/wAAUCGM/QAAQJKtPgEAgLST/AMAQJKtPgEAgLST/AMAQJKtPgEAgLST/AMAQJLkHwAASDvJPwAAJBXs9gMAAKSc5B8AAJLM/AMAAGkn+QcAgKRW/IZfzT+UaMRFU2P5e2s2Ov+tAwbGBcceWoaKABrHmO+MirOrx0SvXj3i+RdeibPPHh9P/25uucsCGpHmH0r0y/OPj3wiEXht+aoY87Nfx2F7/1MZqwLYMkcf/fW44qcT4l+/f0HM/v28OH30ifHA/bfEngMPirfe+mO5y4PmVTDzD/yvrl22im5VnTccTy5eEn26bxtD/vFz5S4NoMF+eObpMW367TFt+m3x0kuvxdnnjI+33v5jjPnOSeUuDUh455134oQTTojtttsuttpqq/jCF74QCxYsKPp6yT9sgXXr6+LBuS/ECYcMiUwmU+5yABqkffv2sffee8Xl/3VtvfOzZj0RQ780pExVQRm10Jn/v/zlL7HvvvvGwQcfHA899FD06NEjXn/99dh2222LXqOszf/bb78dkydPjtmzZ8eKFSsik8lEz549Y9iwYTFmzJjo06fPZ66Ry+Uil8vVO5dfuy6yHdo3VdmwwWPPvhYffJSLr39pQLlLAWiwbt26Rrt27WLlu6vqnV+5clX03L5HmaqCyrCpXjabzUY2m93os5dffnn06dMnpk+fvuHcTjvtVNL9yjb28/TTT0f//v3jnnvuiYEDB8ZJJ50UJ5xwQgwcODBmzpwZAwYMiN/97nefuU5NTU1UVVXVO/7rtoeb4U8AETNnL459d+8XPbbdutylAGyxwt+91TSTyWx0DipBIZ9vtmNTvWxNTc0m67rvvvtiyJAhcfTRR0ePHj1i0KBBMXXq1JL+bGVL/n/4wx/G6NGj48orr9zs988666yYN2/ep64zbty4qK6urncu/7ubG61O2Jw//nlN/OGlZfHTM75e7lIAtsiqVe/F+vXro+f23eud7959u1j57p/KVBVUhk31sptK/SMilixZEpMnT47q6uq44IILYu7cufGDH/wgstlsnHRScc/nlK35f+655+KWW27Z7Pe/853vxM9//vPPXGdTvxb5yMgPzeDe3z8XXbtsFfvvsXO5SwHYIuvWrYtnnvmfOPSQA+Lee//vt+eHHnpA3H//b8pYGbR+mxvx2ZR8Ph9DhgyJ//iP/4iIiEGDBsXzzz8fkydPLrr5L9vYT69evWL27Nmb/f7vf//76NWrVzNWBMXL5wtx35zn4sgv7R7t2to0C0i/K6+aGqed+u04edQxsdtuu8ZP/2tC7Nhnh7h+it+mU4HyheY7StCrV6/Yfffd653r379/LFu2rOg1ypb8n3POOTFmzJhYsGBBHHbYYdGzZ8/IZDKxYsWKmDVrVtxwww0xadKkcpUHn2rOS2/G8vc+iJFD9yh3KQCN4le/ui+26/oPcdGFP4xevXrEc8+/HEd+/cRYtuydcpcG/K999903Xn755XrnXnnllejbt2/Ra2QKZXyS54477ogrr7wyFixYEHV1dRER0bZt2xg8eHBUV1fHt771rQat+9GjUxqzTICy6zJiYrlLAGhU69e23B8say85odnu1fmizY/B/7158+bFsGHDYuLEifGtb30r5s6dG6effnpMmTIljj/++KLWKGvz/zfr1q2LVas+2V6sW7du0b79ls3sa/6B1kbzD7Q2mv9PlNL8R0Q88MADMW7cuHj11VejX79+UV1dHaeffnrR17eIl3y1b9/efD8AAC1DC33JV0TEEUccEUcccUSDr/ekIgAAVIgWkfwDAECLkc+Xu4ImI/kHAIAKIfkHAICkFjzzv6Uk/wAAUCEk/wAAkFQw8w8AAKSc5B8AAJLM/AMAAGkn+QcAgISCff4BAIC0k/wDAECSmX8AACDtNP8AAFAhjP0AAECSsR8AACDtJP8AAJBUsNUnAACQcpJ/AABIMvMPAACkneQfAAASCpJ/AAAg7ST/AACQJPkHAADSTvIPAABJefv8AwAAKSf5BwCAJDP/AABA2kn+AQAgSfIPAACkneQfAAASCgXJPwAAkHKSfwAASDLzDwAApJ3mHwAAKoSxHwAASDL2AwAApJ3kHwAAEgqSfwAAIO0k/wAAkCT5BwAA0k7yDwAASflyF9B0JP8AAFAhJP8AAJBgtx8AACD1JP8AAJAk+QcAANJO8g8AAEl2+wEAANJO8g8AAAl2+wEAAFJP8g8AAElm/gEAgLTT/AMAQIUw9gMAAAke+AUAAFJP8w8AAEn5ZjxKMGHChMhkMvWO7bffvqQ1jP0AAEBKDBgwIB555JENX7dt27ak6zX/AACQUGjBW322a9eu5LQ/ydgPAACUSS6XizVr1tQ7crncZj//6quvRu/evaNfv35x7LHHxpIlS0q6n+YfAACSmnHmv6amJqqqquodNTU1myxrn332iZtuuil+85vfxNSpU2PFihUxbNiw+POf/1z0Hy1TKBRa3V5GHz06pdwlADSqLiMmlrsEgEa1fu075S5hs/58+IHNdq+t7/7tRkl/NpuNbDb7mdfW1tbGLrvsEuedd15UV1cXdT8z/wAAkNCcM//FNvqb0rlz59hzzz3j1VdfLfoaYz8AAJBCuVwuXnzxxejVq1fR12j+AQAgqYXu83/OOefEE088EUuXLo0//OEP8c1vfjPWrFkTo0aNKnoNYz8AAJACb7/9dnz729+OVatWRffu3eNLX/pSzJkzJ/r27Vv0Gpp/AABIaKn7/N9+++1bvIaxHwAAqBCSfwAASGipyX9jkPwDAECFkPwDAECC5B8AAEg9yT8AACQVMuWuoMlI/gEAoEJo/gEAoEIY+wEAgAQP/AIAAKkn+QcAgIRC3gO/AABAykn+AQAgwcw/AACQepJ/AABIKHjJFwAAkHaSfwAASDDzDwAApJ7kHwAAEuzzDwAApJ7kHwAAEgqFclfQdCT/AABQIST/AACQYOYfAABIPck/AAAkSP4BAIDU0/wDAECFMPYDAAAJtvoEAABST/IPAAAJHvgFAABST/IPAAAJhYLkHwAASDnJPwAAJBTy5a6g6Uj+AQCgQkj+AQAgIW/mHwAASDvJPwAAJNjtBwAASD3JPwAAJHjDLwAAkHqSfwAASCgUyl1B05H8AwBAhZD8AwBAgpl/AAAg9ST/AACQ4A2/AABA6mn+AQCgQjSo+b/55ptj3333jd69e8ebb74ZERGTJk2Ke++9t1GLAwCA5lYoZJrtaG4lN/+TJ0+O6urq+NrXvhbvv/9+1NXVRUTEtttuG5MmTWrs+gAAgEZScvN/9dVXx9SpU+PCCy+Mtm3bbjg/ZMiQWLx4caMWBwAAza1QaL6juZXc/C9dujQGDRq00flsNhu1tbWNUhQAAND4St7qs1+/frFo0aLo27dvvfMPPfRQ7L777o1WGAAAlENr3uqz5Ob/3HPPjbFjx8bHH38chUIh5s6dG7fddlvU1NTEDTfc0BQ1AgAAjaDk5v+UU06J9evXx3nnnRd//etf47jjjosddtghrrrqqjj22GObokYAAGg25diFp7k06A2/p59+epx++umxatWqyOfz0aNHj8auCwAAaGRb9JKvbt26afwBAGhV0rDbT01NTWQymTjrrLNKuq5BD/xmMpv/VciSJUtKXRIAACjSvHnzYsqUKbHXXnuVfG3Jzf/f/3Sxbt26WLhwYTz88MNx7rnnllwAAAC0JC15t58PP/wwjj/++Jg6dWpccsklJV9fcvN/5plnbvL8tddeG/Pnzy+5AAAAqFS5XC5yuVy9c9lsNrLZ7CY/P3bs2Dj88MPj0EMPbZ7mf3NGjBgR48aNi+nTpzfWkg32/KgHy10CQKP66I9PlbsEgIrRnLv91NTUxMSJE+udGz9+fEyYMGGjz95+++3xzDPPxLx58xp8v0Zr/n/9619H165dG2s5AABo9caNGxfV1dX1zm0q9X/rrbfizDPPjN/+9rfRsWPHBt+v5OZ/0KBB9R74LRQKsWLFivjTn/4U1113XYMLAQCAlqA5Z/4/bcQnacGCBbFy5coYPHjwhnN1dXXx5JNPxjXXXBO5XC7atm37meuU3PyPHDmy3tdt2rSJ7t27x0EHHRS77bZbqcsBAACf4ZBDDonFixfXO3fKKafEbrvtFueff35RjX9Eic3/+vXrY6eddoqvfOUrsf3225dyKQAApMIWbL/fZLp06RJ77LFHvXOdO3eO7bbbbqPzn6akl3y1a9cuvvvd7270RDIAANDylTz2s88++8TChQujb9++TVEPAABQhMcff7zka0pu/r/3ve/F2WefHW+//XYMHjw4OnfuXO/7DXnTGAAAtBQt+SVfW6ro5v/UU0+NSZMmxTHHHBMRET/4wQ82fC+TyUShUIhMJhN1dXWNXyUAALDFim7+b7zxxrjsssti6dKlTVkPAACUVXO+5Ku5Fd38FwqfPPds1h8AANKppJn/5Mu9AACgNcqXu4AmVFLz//nPf/4zfwB47733tqggAACgaZTU/E+cODGqqqqaqhYAACi7QrTeaZeSmv9jjz02evTo0VS1AAAATajo5t+8PwAAlSBfKHcFTadNsR/8224/AABAOhWd/Ofzrfm5ZwAA+ES+Fc/8F538AwAA6VbSA78AANDatebdfiT/AABQIST/AACQ0JqfdJX8AwBAhZD8AwBAgpl/AAAg9ST/AACQYOYfAABIPc0/AABUCGM/AACQYOwHAABIPck/AAAk2OoTAABIPck/AAAk5Ftv8C/5BwCASiH5BwCAhLyZfwAAIO0k/wAAkFAodwFNSPIPAAAVQvIPAAAJ3vALAACknuQfAAAS8hm7/QAAACkn+QcAgAS7/QAAAKkn+QcAgAS7/QAAAKmn+QcAgAph7AcAABLyrXenT8k/AABUCsk/AAAk5KP1Rv+SfwAAqBCSfwAASPCSLwAAIPUk/wAAkGC3HwAAIPUk/wAAkJAvdwFNSPIPAAAVQvIPAAAJdvsBAABST/IPAAAJdvsBAABST/IPAAAJdvsBAABST/IPAAAJkn8AAKCsJk+eHHvttVdss802sc0228TQoUPjoYceKmkNyT8AACQUWuhuP5/73Ofisssui1133TUiIm688cY46qijYuHChTFgwICi1tD8AwBAChx55JH1vr700ktj8uTJMWfOHM0/AAC0dLlcLnK5XL1z2Ww2stnsp15XV1cXv/rVr6K2tjaGDh1a9P3M/AMAQEK+GY+ampqoqqqqd9TU1Gy2tsWLF8fWW28d2Ww2xowZE/fcc0/svvvuRf/ZJP8AAFAm48aNi+rq6nrnPi31/6d/+qdYtGhRvP/++3HXXXfFqFGj4oknnij6BwDNPwAAJDTnVp/FjPgkdejQYcMDv0OGDIl58+bFVVddFddff31R1xv7AQCAlCoUChs9M/BpJP8AAJBQKHcBm3HBBRfEiBEjok+fPvHBBx/E7bffHo8//ng8/PDDRa+h+QcAgBR4991348QTT4zly5dHVVVV7LXXXvHwww/HYYcdVvQamn8AAEjIt9CXfP3iF7/Y4jXM/AMAQIWQ/AMAQEJz7vbT3CT/AABQIST/AACQIPkHAABST/IPAAAJLXWf/8Yg+QcAgAoh+QcAgISWus9/Y5D8AwBAhZD8AwBAgt1+AACA1NP8AwBAhTD2AwAACbb6BAAAUk/yDwAACflWnP1L/gEAoEJI/gEAIMFWnwAAQOpJ/gEAIKH1TvxL/gEAoGJI/gEAIMHMPwAAkHqSfwAASMhnyl1B05H8AwBAhZD8AwBAgjf8AgAAqSf5BwCAhNab+0v+AQCgYkj+AQAgwT7/AABA6kn+AQAgwW4/AABA6mn+AQCgQhj7AQCAhNY79CP5BwCAiiH5BwCABFt9AgAAqSf5BwCABFt9AgAAqSf5BwCAhNab+0v+AQCgYkj+AQAgwW4/AABA6kn+AQAgodCKp/4l/wAAUCEk/wAAkGDmHwAASD3JPwAAJHjDLwAAkHqSfwAASGi9ub/kHwAAKobmHwAAKoSxHwAASPDALwAAkHqSfwAASPCSL2Czth/7LzHk7ZnRZ8Jp5S4FoEHWr6+Ln025Mb7yzZNj8MFHxVePPiUmT/tl5POtuQWCyqT5hy2w1cBdo/vxw+OvLywtdykADfaLX94Zd858MC6o/l7cd+uUqP7eqTH91rvil7++r9ylQVkUmvF/paipqYl//ud/ji5dukSPHj1i5MiR8fLLL5e0huYfGqjNVh1j56t/GG+cd23Ura4tdzkADfbscy/Fwft/KQ4c9sXYoVfPGH7w/jHsi3vH8y+9Wu7SgIQnnngixo4dG3PmzIlZs2bF+vXrY/jw4VFbW3wfovmHBtrx0jNi9aML4oOn/6fcpQBskb33GhB/mL8o3lj2dkREvPTqknjmf56PA4b+c5krg/LIN+NRiocffjhOPvnkGDBgQAwcODCmT58ey5YtiwULFhS9Rot+4Pett96K8ePHx7Rp0zb7mVwuF7lcrt65tYW66JBp29TlUcH+4ev7xVZ77hIvHn5OuUsB2GKnnXB0fPBhbRx53BnRtk2bqMvn4wdnjIqvHXZQuUuDVm9TvWw2m41sNvuZ165evToiIrp27Vr0/Vp08v/ee+/FjTfe+KmfqampiaqqqnrHjA/8mpKm075Xt9hx4uhY+v0ro5BbV+5yALbYQ48+EQ/89rG4fMJ5cef0q+PSi86OGbfdFfc+OKvcpUFZNOfM/6Z62Zqams+usVCI6urq2G+//WKPPfYo+s+WKRQKZXuLwX33ffqDREuWLImzzz476urqNvuZTf209Fz/4yX/NJltv7JP7PqLcVFY/3//v8y0axuFfD4iX4gFOx8dYYcMGtnARVeUuwRasUP+34kx+oRvxbf/5cgN566fcVs88JvH4v7bppaxMlqz9t12LncJm3XKTv/SbPf6+cu3Nij5Hzt2bPz3f/93PP300/G5z32u6PuVdexn5MiRkclk4tN+/shkMp+6xqb+cjT+NKU1Tz8bzx3yg3rn+v30+/Hx6+/E8uvu1vgDqfPxx7nItKn/39s2bdpEvnz5IJRVc/6XvNgRn6Tvf//7cd9998WTTz5ZUuMfUeaxn169esVdd90V+Xx+k8czzzxTzvJgk/K1H8fHLy+rd+Q/ysX6v3wQH7+8rNzlAZTsoH33iak33h5PzJ4b7yx/Nx554ndx0x13xyEHDC13aUBCoVCIf/3Xf4277747HnvssejXr1/Ja5Q1+R88eHA888wzMXLkyE1+/7N+KwAAbLkLfvjduHrqTXHJT66N9/7yfnTv1jWOPupr8d1Tjit3aVAWLfW3XmPHjo1bb7017r333ujSpUusWLEiIiKqqqqiU6dORa1R1pn/p556Kmpra+OrX/3qJr9fW1sb8+fPjwMPPLCkded/bmQjVAfQcpj5B1qbljzzf2LfbzTbvW5+8+6iP7u5cfjp06fHySefXNQaZU3+999//0/9fufOnUtu/AEAYEu0zNw/GmUipkVv9QkAADSeFv2SLwAAaG75Fpv9bznJPwAAVAjJPwAAJBQk/wAAQNpp/gEAoEIY+wEAgIR8uQtoQpJ/AACoEJJ/AABIsNUnAACQepJ/AABIsNUnAACQepJ/AABIsNsPAACQepJ/AABIKBTM/AMAACkn+QcAgAT7/AMAAKkn+QcAgAS7/QAAAKkn+QcAgARv+AUAAFJP8g8AAAl2+wEAAFJP8w8AABXC2A8AACQUCsZ+AACAlJP8AwBAgpd8AQAAqSf5BwCABC/5AgAAUk/yDwAACV7yBQAApJ7kHwAAEuzzDwAApJ7kHwAAEsz8AwAAqSf5BwCABPv8AwAAqSf5BwCAhLzdfgAAgLST/AMAQELrzf0l/wAAUDE0/wAAUCGM/QAAQIKXfAEAAKkn+QcAgATJPwAAkHqSfwAASCh4yRcAAJB2kn8AAEgw8w8AAKSe5B8AABIKkn8AACDtJP8AAJBgtx8AACD1JP8AAJBgtx8AAKCsnnzyyTjyyCOjd+/ekclkYubMmSWvofkHAICEQqHQbEcpamtrY+DAgXHNNdc0+M9m7AcAAMokl8tFLperdy6bzUY2m93osyNGjIgRI0Zs0f0k/wAAkJCPQrMdNTU1UVVVVe+oqalpsj+b5B8AAMpk3LhxUV1dXe/cplL/xqL5BwCAhOZ8w+/mRnyairEfAACoEJp/AACoEMZ+AAAgIV/iFpzN5cMPP4zXXnttw9dLly6NRYsWRdeuXWPHHXcsag3NPwAApMD8+fPj4IMP3vD13x4UHjVqVMyYMaOoNTT/AACQ0JwP/JbioIMOKvnFYH/PzD8AAFQIyT8AACS01Jn/xiD5BwCACiH5BwCAhJY6898YJP8AAFAhJP8AAJBg5h8AAEg9yT8AACSY+QcAAFJP8g8AAAlm/gEAgNST/AMAQIKZfwAAIPUk/wAAkFAo5MtdQpOR/AMAQIXQ/AMAQIUw9gMAAAl5D/wCAABpJ/kHAICEgpd8AQAAaSf5BwCABDP/AABA6kn+AQAgwcw/AACQepJ/AABIyEv+AQCAtJP8AwBAQsFuPwAAQNpJ/gEAIMFuPwAAQOpJ/gEAIMEbfgEAgNST/AMAQIKZfwAAIPUk/wAAkOANvwAAQOpp/gEAoEIY+wEAgAQP/AIAAKkn+QcAgAQv+QIAAFJP8g8AAAlm/gEAgNST/AMAQIKXfAEAAKkn+QcAgISC3X4AAIC0k/wDAECCmX8AACD1JP8AAJBgn38AACD1JP8AAJBgtx8AACD1JP8AAJBg5h8AAEg9zT8AAFQIzT8AACQUCoVmOxriuuuui379+kXHjh1j8ODB8dRTTxV9reYfAABS4o477oizzjorLrzwwli4cGHsv//+MWLEiFi2bFlR12v+AQAgodCMR6muuOKKOO2002L06NHRv3//mDRpUvTp0ycmT55c1PWafwAAKJNcLhdr1qypd+RyuU1+du3atbFgwYIYPnx4vfPDhw+P2bNnF3W/VrnV55C3Z5a7BCpALpeLmpqaGDduXGSz2XKXA7DF/LsGn1i/9p1mu9eECRNi4sSJ9c6NHz8+JkyYsNFnV61aFXV1ddGzZ89653v27BkrVqwo6n6ZQmveyBSa0Jo1a6KqqipWr14d22yzTbnLAdhi/l2D5pfL5TZK+rPZ7CZ/AP/jH/8YO+ywQ8yePTuGDh264fyll14aN998c7z00kufeb9WmfwDAEAabK7R35Ru3bpF27ZtN0r5V65cudFvAzbHzD8AAKRAhw4dYvDgwTFr1qx652fNmhXDhg0rag3JPwAApER1dXWceOKJMWTIkBg6dGhMmTIlli1bFmPGjCnqes0/NFA2m43x48d7KA5oNfy7Bi3fMcccE3/+85/jxz/+cSxfvjz22GOPePDBB6Nv375FXe+BXwAAqBBm/gEAoEJo/gEAoEJo/gEAoEJo/gEAoEJo/qGBrrvuuujXr1907NgxBg8eHE899VS5SwJokCeffDKOPPLI6N27d2QymZg5c2a5SwKaiOYfGuCOO+6Is846Ky688MJYuHBh7L///jFixIhYtmxZuUsDKFltbW0MHDgwrrnmmnKXAjQxW31CA+yzzz6x9957x+TJkzec69+/f4wcOTJqamrKWBnAlslkMnHPPffEyJEjy10K0AQk/1CitWvXxoIFC2L48OH1zg8fPjxmz55dpqoAAD6b5h9KtGrVqqirq4uePXvWO9+zZ89YsWJFmaoCAPhsmn9ooEwmU+/rQqGw0TkAgJZE8w8l6tatW7Rt23ajlH/lypUb/TYAAKAl0fxDiTp06BCDBw+OWbNm1Ts/a9asGDZsWJmqAgD4bO3KXQCkUXV1dZx44okxZMiQGDp0aEyZMiWWLVsWY8aMKXdpACX78MMP47XXXtvw9dKlS2PRokXRtWvX2HHHHctYGdDYbPUJDXTdddfFf/7nf8by5ctjjz32iCuvvDIOOOCAcpcFULLHH388Dj744I3Ojxo1KmbMmNH8BQFNRvMPAAAVwsw/AABUCM0/AABUCM0/AABUCM0/AABUCM0/AABUCM0/AABUCM0/AABUCM0/AABUCM0/QAszYcKE+MIXvrDh65NPPjlGjhzZ7HW88cYbkclkYtGiRc1+bwCahuYfoEgnn3xyZDKZyGQy0b59+9h5553jnHPOidra2ia971VXXRUzZswo6rMadgA+TbtyFwCQJl/96ldj+vTpsW7dunjqqadi9OjRUVtbG5MnT673uXXr1kX79u0b5Z5VVVWNsg4ASP4BSpDNZmP77bePPn36xHHHHRfHH398zJw5c8OozrRp02LnnXeObDYbhUIhVq9eHWeccUb06NEjttlmm/jyl78czz77bL01L7vssujZs2d06dIlTjvttPj444/rff/vx37y+Xxcfvnlseuuu0Y2m40dd9wxLr300oiI6NevX0REDBo0KDKZTBx00EEbrps+fXr0798/OnbsGLvttltcd9119e4zd+7cGDRoUHTs2DGGDBkSCxcubMS/OQBaAsk/wBbo1KlTrFu3LiIiXnvttbjzzjvjrrvuirZt20ZExOGHHx5du3aNBx98MKqqquL666+PQw45JF555ZXo2rVr3HnnnTF+/Pi49tprY//994+bb745fvazn8XOO++82XuOGzcupk6dGldeeWXst99+sXz58njppZci4pMG/otf/GI88sgjMWDAgOjQoUNEREydOjXGjx8f11xzTQwaNCgWLlwYp59+enTu3DlGjRoVtbW1ccQRR8SXv/zluOWWW2Lp0qVx5plnNvHfHgDNTfMP0EBz586NW2+9NQ455JCIiFi7dm3cfPPN0b1794iIeOyxx2Lx4sWxcuXKyGazERHxk5/8JGbOnBm//vWv44wzzohJkybFqaeeGqNHj46IiEsuuSQeeeSRjdL/v/nggw/iqquuimuuuSZGjRoVERG77LJL7LfffhERG+693Xbbxfbbb7/hun//93+Pn/70p/GNb3wjIj75DcELL7wQ119/fYwaNSp++ctfRl1dXUybNi222mqrGDBgQLz99tvx3e9+t7H/2gAoI2M/ACV44IEHYuutt46OHTvG0KFD44ADDoirr746IiL69u27ofmOiFiwYEF8+OGHsd1228XWW2+94Vi6dGm8/vrrERHx4osvxtChQ+vd4++/TnrxxRcjl8tt+IGjGH/605/irbfeitNOO61eHZdcckm9OgYOHBhbbbVVUXUAkE6Sf4ASHHzwwTF58uRo37599O7du95DvZ07d6732Xw+H7169YrHH398o3W23XbbBt2/U6dOJV+Tz+cj4pPRn3322afe9/42nlQoFBpUDwDpovkHKEHnzp1j1113Leqze++9d6xYsSLatWsXO+200yY/079//5gzZ06cdNJJG87NmTNns2v+4z/+Y3Tq1CkeffTRDaNCSX+b8a+rq9twrmfPnrHDDjvEkiVL4vjjj9/kurvvvnvcfPPN8dFHH234AePT6gAgnYz9ADSRQw89NIYOHRojR46M3/zmN/HGG2/E7Nmz46KLLor58+dHRMSZZ54Z06ZNi2nTpsUrr7wS48ePj+eff36za3bs2DHOP//8OO+88+Kmm26K119/PebMmRO/+MUvIiKiR48e0alTp3j44Yfj3XffjdWrV0fEJy8Oq6mpiauuuipeeeWVWLx4cUyfPj2uuOKKiIg47rjjok2bNnHaaafFCy+8EA8++GD85Cc/aeK/IQCam+YfoIlkMpl48MEH44ADDohTTz01Pv/5z8exxx4bb7zxRvTs2TMiIo455pi4+OKL4/zzz4/BgwfHm2+++ZkP2f7oRz+Ks88+Oy6++OLo379/HHPMMbFy5cqIiGjXrl387Gc/i+uvvz569+4dRx11VEREjB49Om644YaYMWNG7LnnnnHggQfGjBkzNmwNuvXWW8f9998fL7zwQgwaNCguvPDCuPzyy5vwbweAcsgUDHoCAEBFkPwDAECF0PwDAECF0PwDAECF0PwDAECF0PwDAECF0PwDAECF0PwDAECF0PwDAECF0PwDAECF0PwDAECF0PwDAECF+P+aL62TrPOONgAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 1000x700 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Make predictions with the best model\n",
        "\n",
        "model.load_state_dict(torch.load(path))\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    logits = model(data)\n",
        "    preds = logits.max(dim=1)[1]\n",
        "\n",
        "# Create a mask for the fake and real news\n",
        "news_mask = ((data.y == 0) | (data.y == 1)) & data.test_mask\n",
        "\n",
        "# Apply the mask to the labels and predictions\n",
        "labels_news = data.y[news_mask]\n",
        "preds_news = preds[news_mask]\n",
        "\n",
        "accuracy = accuracy_score(labels_news.cpu(), preds_news.cpu())\n",
        "f1 = f1_score(labels_news.cpu(), preds_news.cpu(), average='weighted')\n",
        "\n",
        "print(f'Final Test Accuracy: {accuracy}')\n",
        "print(f'Final Test F1 Score: {f1}')\n",
        "\n",
        "report = classification_report(labels_news.cpu(), preds_news.cpu(), digits=4)\n",
        "print(report)\n",
        "\n",
        "cm = confusion_matrix(labels_news.cpu(), preds_news.cpu())\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "sns.heatmap(cm, annot=True, fmt='d')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LBNDZXDnJmnM"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
